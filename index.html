<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-122759872-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        
        gtag('config', 'UA-122759872-1');
        </script>
    
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <link rel="shortcut icon" HREF="index/favicon.ico">
            <title>Libing Zeng</title>
            <link rel="stylesheet" type="text/css" href="./index/main.css">
                <link href="./index/css" rel="stylesheet">
                    <style>
                        .quote{
                            font-family: 'Dawning of a New Day';
                            font-weight:bold;
                            font-size:30px;
                        }
                    </style>
                     
</head>

<body>
    <div id="main">
        
        <div class="name">
            Libing Zeng (曾立兵)
        </div>
        
        <div>
            <img src="./index/libingzeng4.png" style="width:205px; height:256px" class="portrait"><br>
                &nbsp;&nbsp;&nbsp;
                
                <div class="bio_format">
                    <p> Howdy!
                    </p>
                    
                    <p> I am a fourth-year Ph.D. student, supervised by Dr. <a href="http://faculty.cs.tamu.edu/nimak/">Nima Khademi Kalantari</a>, in <a href="https://engineering.tamu.edu/cse/index.html">Computer Science and Engineering</a> department at <a href="https://www.tamu.edu/">Texas A&M University</a>. My current research interests are using deep learning techniques to solve variours problems in 3D reconstruction, neural rendering, view synthesis, and video denoising.

                    </p>
                    
                    <p> Previously, I worked on light transport simulation problems under the supervision of Dr. <a href="http://www.liyiwei.org/">Li-Yi Wei</a>.
                    </p>
                    
                    <p> Prior to that, I got my bachelor degree in Electronic Information Engineering from <a href="http://www-en.hnu.edu.cn/">Hunan University</a> where I worked with Dr. <a href="http://eeit.hnu.edu.cn/info/1411/4632.htm">Shaoyuan Wang</a>.
                    </p>

                    <!-- Here is my <a href="index/cv_libingzeng.pdf">CV</a>&nbsp; -->
                    Here is my &nbsp;
                    <a href="mailto:libingzeng@tamu.edu"><img src="index/gmail_logo.png" width="25px"></a>&nbsp;
                    <a href="https://github.com/libingzeng" target="blank"><img src="index/github_logo.png" width="25px"></a>&nbsp;
                    <a href="https://blog.csdn.net/libing_zeng" target="blank"><img src="index/csdn_logo.png" width="25px"></a>&nbsp;
                </div>
        </div>
        
        <!--
        <div>
            <span class="category">NEWS</span>
            <hr class="line">
            <div align=left
                style='
                border: solid 2px grey;
                width: 900px;
                height: 200px;
                overflow: scroll;
                scrollbar-face-color: #889B9F;
                scrollbar-shadow-color: #3D5054;
                scrollbar-highlight-color: #C3D6DA;
                scrollbar-3dlight-color: #3D5054;
                scrollbar-darkshadow-color: #85989C;
                scrollbar-track-color: #95A6AA;
                scrollbar-arrow-color: #FFD6DA;
                '>
                
                <ul class="item_content">
                    <li>
                        <font color="black"><b>[08/2019] He starts his Ph.D. study in TAMU.</b></font>
                    </li>
                    <li>
                        <font color="black"><span>[03/2019] He gets a Ph.D. offer in computer graphics from UCSB.</span></font>
                    </li>
                    <li>
                        <font color="black"><span>[02/2019] He gets a Ph.D. offer in computer graphics from TAMU.</span></font>
                    </li>
                    <li>
                        <font color="black"><span>[12/2018] He is looking for Ph.D. position in computer graphics in the United States.</span></font>
                    </li>
                </ul>

            </div>
        </div>
        -->

        <div>
            <span class="category">PAPERS</span>
            <hr class="line">
            <ol style="padding:0px;list-style-type:none">
                
                <li class="item_format" style="position:relative">
                    <!-- <img src="./research/landmark_detection.gif" class="img_format" style="width:550px;height:300px;"> -->
                    <img src="./research/landmark_detection.gif" class="img_format">
                        <div class="title_format">
                            <b>3D-aware Facial Landmark Detection via Multiview Consistent Training on Synthetic Data</b>
                            <span class="author_format"><b>Libing Zeng</b>, Lele Chen, Wentao Bao, Zhong Li, Yi Xu, Junsong Yuan, Nima Khademi Kalantari.</span>
                            <span class="venue_format"><em>In Submission</em></span>
                            <div class="link_format">
                                [<a class="btn btn-default abstract" abstract="In this paper, by leveraging synthetic data, we propose a novel multi-view consistent learning strategy to improve 3D facial landmark detection accuracy on in-the-wild images. The proposed 3D-aware module can be plugged into any learning-based landmark detection algorithm.">Abstract</a>]
                                <!-- [<a href="https://people.engr.tamu.edu/nimak/Papers/ICCP2021_denoising/index.html">Project</a>]
                                [<a href="https://arxiv.org/abs/2103.02861">Paper</a>]
                                [<a href="https://github.com/avinashpaliwal/MaskDnGAN">Code</a>]
                                [<a href="https://www.youtube.com/watch?v=PXbYS4AoJiQ&t=5402s">Talk</a>] -->
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>

                <li class="item_format" style="position:relative">
                    <!-- <img src="./research/egocentric.gif" class="img_format" style="width:550px;height:300px;"> -->
                    <img src="./research/egocentric.gif" class="img_format">
                        <div class="title_format">
                            <b>Uncertainty-aware State Space Transformer for Egocentric 3D Trajectory Forecasting</b>
                            <span class="author_format">Wentao Bao, Lele Chen, <b>Libing Zeng</b>, Zhong Li, Yi Xu, Junsong Yuan, Yu Kong.</span>
                            <span class="venue_format"><em>In Submission</em></span>
                            <div class="link_format">
                                [<a class="btn btn-default abstract" abstract="In this paper, we set up an egocentric 3D hand trajectory forecasting task that aims to predict hand trajectories in a 3D space from early observed RGB videos in a first-person view.">Abstract</a>]
                                <!-- [<a href="https://people.engr.tamu.edu/nimak/Papers/ICCP2021_denoising/index.html">Project</a>]
                                [<a href="https://arxiv.org/abs/2103.02861">Paper</a>]
                                [<a href="https://github.com/avinashpaliwal/MaskDnGAN">Code</a>]
                                [<a href="https://www.youtube.com/watch?v=PXbYS4AoJiQ&t=5402s">Talk</a>] -->
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>
                        
                <li class="item_format" style="position:relative">
                    <!-- <img src="./research/depth_estimation.png" class="img_format" style="width:550px;height:300px;"> -->
                    <img src="./research/depth_estimation.png" class="img_format">
                        <div class="title_format">
                            <b>Test-Time Optimization for Video Depth Estimation Using Pseudo Reference Depth
                            </b>
                            <span class="author_format"><b>Libing Zeng</b>, Nima Khademi Kalantari.</span>
                            <span class="venue_format"><em>Computer Graphics Forum (CGF) 2023</em></span>
                            <div class="link_format">
                                [<a class="btn btn-default abstract" abstract="In this paper, we propose a learning-based test-time optimization approach for reconstructing geometrically consistent depth maps from a monocular video. Specifically, we optimize an existing single image depth estimation network on the test example at hand. We do so by introducing pseudo reference depth maps which are computed based on the observation that the optical flow displacement for an image pair should be consistent with the displacement obtained by depth-reprojection. Additionally, we discard inaccurate pseudo reference depth maps using a simple median strategy and propose a way to compute a confidence map for the reference depth. We use our pseudo reference depth and the confidence map to formulate a loss function for performing the test-time optimization in an efficient and effective manner. ">Abstract</a>]
                                <!-- [<a href="https://people.engr.tamu.edu/nimak/Papers/ICCP2021_denoising/index.html">Project</a>]
                                [<a href="https://arxiv.org/abs/2103.02861">Paper</a>]
                                [<a href="https://github.com/avinashpaliwal/MaskDnGAN">Code</a>]
                                [<a href="https://www.youtube.com/watch?v=PXbYS4AoJiQ&t=5402s">Talk</a>] -->
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>
                
                <li class="item_format" style="position:relative">
                    <!-- <img src="./research/iccp2021_denoising.png" class="img_format" style="width:550px;height:300px;"> -->
                    <img src="./research/iccp2021_denoising.png" class="img_format">
                        <div class="title_format">
                            <b>Multi-Stage Raw Video Denoising with Adversarial Loss and Gradient Mask</b>
                            <span class="author_format">Avinash Paliwal, <b>Libing Zeng</b>, Nima Khademi Kalantari.</span>
                            <span class="venue_format"><em>International Conference on Computational Photography (ICCP) 2021</em></span>
                            <div class="link_format">
                                [<a class="btn btn-default abstract" abstract="In this paper, we propose a learning-based approach for denoising raw videos captured under low lighting conditions. We propose to do this by first explicitly aligning the neighboring frames to the current frame using a convolutional neural network (CNN). We then fuse the registered frames using another CNN to obtain the final denoised frame. To avoid directly aligning the temporally distant frames, we perform the two processes of alignment and fusion in multiple stages. ">Abstract</a>]
                                [<a href="https://people.engr.tamu.edu/nimak/Papers/ICCP2021_denoising/index.html">Project</a>]
                                [<a href="https://arxiv.org/abs/2103.02861">Paper</a>]
                                [<a href="https://github.com/avinashpaliwal/MaskDnGAN">Code</a>]
                                [<a href="https://www.youtube.com/watch?v=PXbYS4AoJiQ&t=5402s">Talk</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>
                 
                <li class="item_format" style="position:relative">
                    <!-- <img src="./research/pfmlt.jpg" class="img_format" style="width:550px;height:300px;"> -->
                    <img src="./research/pfmlt.jpg" class="img_format">
                        <div class="title_format">
                            <b>Rectifying Proposal Failures in Metropolis Light Transport</b>
                            <span class="author_format"><b>Libing Zeng</b>, Li-Yi Wei.</span>
                            <span class="venue_format"><em>Preprint (HAL)</em></span>
                            <div class="link_format">
                                [<a class="btn btn-default abstract" abstract="Based on MMLT, we propose a novel algorithm, Rectifying Proposal Failure MLT (RPFMLT), which distinguishes proposal failure paths from normal proposed paths and excludes them from the states of Markov chain. PFMLT better approximates the original path distributions especially for high proposal rejection rates, and can be easily integrated with various MLT algorithms.">Abstract</a>]
                                [<a href="https://hal.archives-ouvertes.fr/hal-02548744">Paper</a>]
                                [<a href="https://github.com/libingzeng/pbrt-v3">Code_pbrt</a>]
                                [<a href="https://github.com/libingzeng/tungsten">Code_tungsten</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>

            </ol>
        </div>

        <div>
            <span class="category">PROJECTS</span>
            <hr class="line">
            <ol style="padding:0px;list-style-type:none">
                
                <li class="item_format" style="position:relative">
                    <!-- <img src="./research/bart_robot1.jpg" class="img_format" style="width:550px;height:300px;"> -->
                    <img src="./research/bart_robot1.jpg" class="img_format">
                        <div class="title_format">
                            <b>A Renderer Written from the Scratch (BART Animations with High-Frequency Textures)</b>
                            <span class="author_format">Supervised by Dr. Li-Yi Wei.</span>
                            <span class="venue_format"><em>Exercises</em></span>
                            <div class="link_format">
                                [<a class="btn btn-default abstract" abstract="This renderer mainly has two components. First, parsing animation description files (AFF) without using flex and bison; Second, rendering the three animations of BART with much less artifacts than the original ones. Some key implementations for reducing artifacts: Multi-Jittered sampler, Gaussian filter for reconstruction, Mipmap and EWA filter for texture anti-aliasing. ">Abstract</a>]
                                [<a href="https://github.com/libingzeng/BART-Animations">Project</a>]
                                [<a href="https://youtu.be/yfTIEGcqGfU">Animation_robot</a>]
                                [<a href="https://youtu.be/2veK2uj-yFk">Animation_kitchen</a>]
                                [<a href="https://youtu.be/U0Dylgw_qUk">Animation_museum</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>
                
                <li class="item_format" style="position:relative">
                    <!-- <img src="./research/rtgu_global.jpg" class="img_format" style="width:550px;height:300px;"> -->
                    <img src="./research/rtgu_global.jpg" class="img_format">
                        <div class="title_format">
                            <b>A Renderer Extended from the Book, Ray Tracing from the Ground Up</b>
                            <span class="author_format">Self-study</span>
                            <span class="venue_format"><em>Exercises</em></span>
                            <div class="link_format">
                                [<a class="btn btn-default abstract" abstract="He read the book and extended it from the following aspects. Objects: part of sphere, part of tori, globe, and so on. Tessellation: sphere, horn, rotational sweeping surfaces, bezier patches (Utah teapot). 2D texture: solid cylinder checker, sphere checker. Scene building: several scenes were built and the corresponding resultant images were produced.">Abstract</a>]
                                [<a href="https://github.com/libingzeng/RayTraceGroundUp">Project</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>
                
                <li class="item_format" style="position:relative">
                    <!-- <img src="./research/nontriangulated_surfaces.png" class="img_format" style="width:550px;height:300px;"> -->
                    <img src="./research/nontriangulated_surfaces.png" class="img_format">
                        <div class="title_format">
                            <b>A Renderer with Implementations of Various NON-TRIANGULATE Surfaces</b>
                            <span class="author_format">Self-study</span>
                            <span class="venue_format"><em>Exercises</em></span>
                            <div class="link_format">
                                [<a class="btn btn-default abstract" abstract="This render is based on the framework of Peter Shirley's “ray tracing in one weekend” and is extended with tracing almost all of the NON-TRIANGULATE surfaces mentioned in the book, An Introduction to Ray Tracing. ">Abstract</a>]
                                [<a href="https://github.com/libingzeng/AnIntroductionToRayTracing">Project</a>]
                            </div>
                        </div>
                        <div style="clear:both;"></div>
                </li>
 
            </ol>
        </div>
        
        
        <div>
            <span class="category">TEACHING</span>
            <hr class="line">
            <ul class="item_content">
                <li>
                    <a href="https://people.engr.tamu.edu/sueda/courses/CSCE441/2022S/index.html"> 2022 SPRING CSCE 441: COMPUTER GRAPHICS</a>
                    <span class="author_format">Instructor: Dr. <a href="https://people.engr.tamu.edu/sueda/index.html"> Shinjiro Sueda </a></span>
                </li>
                <li>
                    <a href="https://people.engr.tamu.edu/djimenez/classes/312/index.html"> 2021 FALL CSCE 312: COMPUTER ORGANIZATION</a>
                    <span class="author_format">Instructor: Dr. <a href="https://people.engr.tamu.edu/djimenez/index.html"> Daniel A. Jiménez </a></span>
                </li>
            </ul>
        </div>
        
        
        <div>
            <span class="category">OPEN SOURCE</span>
            <hr class="line">
            <ul class="item_content">
                <li>
                    <b>GitHub: </b>
                    <a href="https://blog.csdn.net/libing_zeng" target="blank"><img src="index/github_logo.png" width="25px"></a>
                </li>
                <li>
                    <b>Blog: </b>
                    <a href="https://blog.csdn.net/libing_zeng" target="blank"><img src="index/csdn_logo.png" width="25px"></a>
                    <span class="author_format">There are over 200 technical reports about my journery of computer graphics (written in simplified Chinese).</span>
                    <span class="author_format">Also, this blog has over 800 followers and over 1.6 million visitors now.</span>

                    
                </li>
            </ul>
        </div>
       
        <div>
            <span class="category">COMPUTER SKILLS</span>
            <hr class="line">
            <ul class="item_content">
                <li>
                    <b>Languages</b>
                    <span class="author_format">PyTorch, Python, C++, and C</span>
                </li>
            </ul>
        </div>
        
<!--         
        <div>
            <span class="category">爱好</span>
            <hr class="line">
            <ul class="item_content">
                <li>
                    <b>健身</b>
                </li>
                <li>
                    <b>篮球</b>
                </li>
                <li>
                    <b>《红楼梦》</b>
                </li>
            </ul>
        </div> -->


        <div>
            <span class="category">ACKNOWLEDGEMENTS</span>
            <hr class="line">
            <ul class="item_content">
                <li>
                    <p class="text-justify">
                        The website template was borrowed from <a href="http://junxnui.github.io/">Jun Xing</a>.
                    </p>
                </li>
            </ul>
            <hr class="line">
        </div>

        <div>
            <a href="https://clustrmaps.com/site/1ax9f"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=2VYrG4d0yS6ggLr46bOONoSDAi04lXmW64rQVnzoZlE&cl=ffffff" /></a>
        </div>

    </div>
    

    <script src="./index/canvas-nest.js_1.0.1_canvas-nest.min.js" opacity="0.6" color="0,68,255" zindex="-1"></script><canvas id="c_n1" width="1287" height="736" style="position: fixed; top: 0px; left: 0px; z-index: -1; opacity: 0.6;"></canvas>

</body></html>
